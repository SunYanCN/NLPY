## 二分类任务评测
- 数据集：[Quora Insincere Questions Classification](https://www.kaggle.com/c/quora-insincere-questions-classification)
- 词向量：[]()
## Fast Text Model
GPU使用情况：341MiB GPU
### 不使用Glove词向量
```python
Epoch 1/30
 - 65s - loss: 0.1407 - F1: 0.4025 - val_loss: 0.1249 - val_F1: 0.4776
Epoch 2/30
 - 66s - loss: 0.1223 - F1: 0.5083 - val_loss: 0.1241 - val_F1: 0.5145
Epoch 3/30
 - 65s - loss: 0.1208 - F1: 0.5173 - val_loss: 0.1242 - val_F1: 0.5003
Epoch 4/30
 - 63s - loss: 0.1200 - F1: 0.5191 - val_loss: 0.1245 - val_F1: 0.5083
Epoch 5/30
 - 64s - loss: 0.1196 - F1: 0.5220 - val_loss: 0.1249 - val_F1: 0.5209
Epoch 6/30
 - 65s - loss: 0.1194 - F1: 0.5236 - val_loss: 0.1246 - val_F1: 0.5067
```

### 使用Glove词向量
```python
Epoch 1/30
 - 66s - loss: 0.1410 - F1: 0.4010 - val_loss: 0.1250 - val_F1: 0.4783
Epoch 2/30
 - 63s - loss: 0.1227 - F1: 0.5069 - val_loss: 0.1242 - val_F1: 0.5095
Epoch 3/30
 - 64s - loss: 0.1212 - F1: 0.5149 - val_loss: 0.1244 - val_F1: 0.4969
Epoch 4/30
 - 63s - loss: 0.1205 - F1: 0.5179 - val_loss: 0.1247 - val_F1: 0.5120
Epoch 5/30
 - 66s - loss: 0.1200 - F1: 0.5180 - val_loss: 0.1250 - val_F1: 0.5218
Epoch 6/30
 - 64s - loss: 0.1198 - F1: 0.5204 - val_loss: 0.1247 - val_F1: 0.5081
```

### Focal loss gamma=2., alpha=.75
```python
Epoch 1/30
 - 67s - loss: 2.2672 - F1: 0.5374 - val_loss: 2.0794 - val_F1: 0.5784
Epoch 2/30
 - 65s - loss: 2.0338 - F1: 0.5913 - val_loss: 2.0754 - val_F1: 0.5843
Epoch 3/30
 - 64s - loss: 2.0023 - F1: 0.5965 - val_loss: 2.0852 - val_F1: 0.5856
Epoch 4/30
 - 64s - loss: 1.9869 - F1: 0.5978 - val_loss: 2.0912 - val_F1: 0.5890
Epoch 5/30
 - 64s - loss: 1.9774 - F1: 0.5994 - val_loss: 2.0965 - val_F1: 0.5889
Epoch 6/30
 - 64s - loss: 1.9701 - F1: 0.6016 - val_loss: 2.0991 - val_F1: 0.5842
```

### Focal loss gamma=2., alpha=.85
```python
Epoch 1/30
 - 64s - loss: 1.9356 - F1: 0.5390 - val_loss: 1.7702 - val_F1: 0.5724
Epoch 2/30
 - 64s - loss: 1.7245 - F1: 0.5811 - val_loss: 1.7695 - val_F1: 0.5813
Epoch 3/30
 - 65s - loss: 1.6939 - F1: 0.5864 - val_loss: 1.7768 - val_F1: 0.5786
Epoch 4/30
 - 66s - loss: 1.6793 - F1: 0.5883 - val_loss: 1.7801 - val_F1: 0.5690
Epoch 5/30
 - 65s - loss: 1.6703 - F1: 0.5886 - val_loss: 1.7875 - val_F1: 0.5726
Epoch 6/30
 - 65s - loss: 1.6632 - F1: 0.5906 - val_loss: 1.7936 - val_F1: 0.5817
```

### Pretrain Embedding Trainable False
```python
Epoch 1/30
 - 34s - loss: 3.6168 - F1: 0.1729 - val_loss: 3.3460 - val_F1: 0.2689
Epoch 2/30
 - 34s - loss: 3.3189 - F1: 0.2778 - val_loss: 3.2693 - val_F1: 0.2856
Epoch 3/30
 - 33s - loss: 3.2668 - F1: 0.2961 - val_loss: 3.2322 - val_F1: 0.3034
Epoch 4/30
 - 34s - loss: 3.2393 - F1: 0.3071 - val_loss: 3.2125 - val_F1: 0.3110
Epoch 5/30
 - 71s - loss: 3.2217 - F1: 0.3141 - val_loss: 3.2037 - val_F1: 0.3325
Epoch 6/30
 - 36s - loss: 3.2099 - F1: 0.3176 - val_loss: 3.1873 - val_F1: 0.3298
Epoch 7/30
 - 33s - loss: 3.2012 - F1: 0.3234 - val_loss: 3.1823 - val_F1: 0.3194
Epoch 8/30
 - 32s - loss: 3.1948 - F1: 0.3262 - val_loss: 3.1746 - val_F1: 0.3354
Epoch 9/30
 - 35s - loss: 3.1896 - F1: 0.3278 - val_loss: 3.1696 - val_F1: 0.3278
Epoch 10/30
 - 35s - loss: 3.1859 - F1: 0.3292 - val_loss: 3.1660 - val_F1: 0.3305
Epoch 11/30
 - 33s - loss: 3.1824 - F1: 0.3298 - val_loss: 3.1622 - val_F1: 0.3331
Epoch 12/30
 - 33s - loss: 3.1800 - F1: 0.3323 - val_loss: 3.1611 - val_F1: 0.3361
Epoch 13/30
 - 33s - loss: 3.1777 - F1: 0.3327 - val_loss: 3.1583 - val_F1: 0.3335
Epoch 14/30
 - 35s - loss: 3.1758 - F1: 0.3336 - val_loss: 3.1587 - val_F1: 0.3334
Epoch 15/30
 - 33s - loss: 3.1742 - F1: 0.3343 - val_loss: 3.1562 - val_F1: 0.3326
Epoch 16/30
 - 33s - loss: 3.1731 - F1: 0.3343 - val_loss: 3.1537 - val_F1: 0.3378
Epoch 17/30
 - 32s - loss: 3.1720 - F1: 0.3351 - val_loss: 3.1531 - val_F1: 0.3423
Epoch 18/30
 - 35s - loss: 3.1709 - F1: 0.3369 - val_loss: 3.1531 - val_F1: 0.3434
Epoch 19/30
 - 33s - loss: 3.1701 - F1: 0.3366 - val_loss: 3.1525 - val_F1: 0.3362
Epoch 20/30
 - 33s - loss: 3.1694 - F1: 0.3370 - val_loss: 3.1506 - val_F1: 0.3369
Epoch 21/30
 - 33s - loss: 3.1685 - F1: 0.3383 - val_loss: 3.1567 - val_F1: 0.3495
Epoch 22/30
 - 33s - loss: 3.1679 - F1: 0.3372 - val_loss: 3.1495 - val_F1: 0.3359
Epoch 23/30
 - 34s - loss: 3.1676 - F1: 0.3384 - val_loss: 3.1501 - val_F1: 0.3449
Epoch 24/30
 - 34s - loss: 3.1670 - F1: 0.3376 - val_loss: 3.1486 - val_F1: 0.3441
Epoch 25/30
 - 34s - loss: 3.1665 - F1: 0.3386 - val_loss: 3.1485 - val_F1: 0.3432
Epoch 26/30
 - 32s - loss: 3.1664 - F1: 0.3383 - val_loss: 3.1473 - val_F1: 0.3440
Epoch 27/30
 - 32s - loss: 3.1660 - F1: 0.3388 - val_loss: 3.1476 - val_F1: 0.3448
Epoch 28/30
 - 33s - loss: 3.1653 - F1: 0.3377 - val_loss: 3.1464 - val_F1: 0.3441
Epoch 29/30
 - 35s - loss: 3.1654 - F1: 0.3398 - val_loss: 3.1469 - val_F1: 0.3442
Epoch 30/30
 - 34s - loss: 3.1652 - F1: 0.3388 - val_loss: 3.1481 - val_F1: 0.3375
```

### ReduceLROnPlateau
```python
Train on 1044898 samples, validate on 261224 samples
Epoch 1/30
 - 64s - loss: 2.2672 - F1: 0.5374 - val_loss: 2.0794 - val_F1: 0.5784
Epoch 2/30
 - 66s - loss: 2.0338 - F1: 0.5913 - val_loss: 2.0754 - val_F1: 0.5843
Epoch 3/30
 - 64s - loss: 2.0023 - F1: 0.5965 - val_loss: 2.0852 - val_F1: 0.5856

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 4/30
 - 64s - loss: 1.9437 - F1: 0.6059 - val_loss: 2.0876 - val_F1: 0.5863

Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 5/30
 - 67s - loss: 1.9287 - F1: 0.6083 - val_loss: 2.0900 - val_F1: 0.5872

Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 6/30
 - 66s - loss: 1.9256 - F1: 0.6085 - val_loss: 2.0912 - val_F1: 0.5870

Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
```

### Train Min length: 1
```python
Epoch 1/30
 - 66s - loss: 2.2574 - F1: 0.5395 - val_loss: 2.0729 - val_F1: 0.5808
Epoch 2/30
 - 64s - loss: 2.0269 - F1: 0.5926 - val_loss: 2.0685 - val_F1: 0.5876
Epoch 3/30
 - 64s - loss: 1.9960 - F1: 0.5976 - val_loss: 2.0790 - val_F1: 0.5871

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 4/30
 - 64s - loss: 1.9373 - F1: 0.6078 - val_loss: 2.0819 - val_F1: 0.5882

Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 5/30
 - 65s - loss: 1.9222 - F1: 0.6101 - val_loss: 2.0836 - val_F1: 0.5903

Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 6/30
 - 63s - loss: 1.9192 - F1: 0.6102 - val_loss: 2.0848 - val_F1: 0.5907

Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
```

### SpatialDropout1D(0.5)(embedding)
```python
Epoch 1/30
 - 75s - loss: 2.3480 - F1: 0.5198 - val_loss: 2.1113 - val_F1: 0.5736
Epoch 2/30
 - 75s - loss: 2.0967 - F1: 0.5818 - val_loss: 2.1008 - val_F1: 0.5766
Epoch 3/30
 - 92s - loss: 2.0646 - F1: 0.5882 - val_loss: 2.1035 - val_F1: 0.5811

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 4/30
 - 118s - loss: 2.0162 - F1: 0.5962 - val_loss: 2.1106 - val_F1: 0.5831

Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 5/30
 - 118s - loss: 2.0046 - F1: 0.5978 - val_loss: 2.1096 - val_F1: 0.5841

Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 6/30
 - 117s - loss: 2.0041 - F1: 0.5991 - val_loss: 2.1103 - val_F1: 0.5841

Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
```

### SpatialDropout1D(0.2, seed=1234)(embedding)
```python
Epoch 1/30
 - 122s - loss: 2.2842 - F1: 0.5337 - val_loss: 2.0836 - val_F1: 0.5789
Epoch 2/30
 - 120s - loss: 2.0484 - F1: 0.5896 - val_loss: 2.0776 - val_F1: 0.5840
Epoch 3/30
 - 120s - loss: 2.0180 - F1: 0.5939 - val_loss: 2.0875 - val_F1: 0.5855

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 4/30
 - 120s - loss: 1.9646 - F1: 0.6041 - val_loss: 2.0905 - val_F1: 0.5873

Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 5/30
 - 94s - loss: 1.9523 - F1: 0.6060 - val_loss: 2.0915 - val_F1: 0.5883

Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 6/30
 - 73s - loss: 1.9497 - F1: 0.6058 - val_loss: 2.0924 - val_F1: 0.5885

Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
```
### batch_size = 1024
```python
Epoch 1/30
 - 53s - loss: 20.7938 - F1: 0.4532 - val_loss: 16.8275 - val_F1: 0.5900
Epoch 2/30
 - 50s - loss: 16.3242 - F1: 0.6019 - val_loss: 16.7828 - val_F1: 0.5824
Epoch 3/30
 - 52s - loss: 15.8555 - F1: 0.6127 - val_loss: 16.4377 - val_F1: 0.6011
Epoch 4/30
 - 52s - loss: 15.6521 - F1: 0.6172 - val_loss: 16.4476 - val_F1: 0.6042

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 5/30
 - 52s - loss: 15.3374 - F1: 0.6227 - val_loss: 16.4616 - val_F1: 0.6048

Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 6/30
 - 52s - loss: 15.2664 - F1: 0.6231 - val_loss: 16.4709 - val_F1: 0.6060

Epoch 00006: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 7/30
 - 49s - loss: 15.2498 - F1: 0.6231 - val_loss: 16.4700 - val_F1: 0.6060

Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
```
